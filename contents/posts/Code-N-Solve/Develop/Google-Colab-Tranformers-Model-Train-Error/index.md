---
title: "ğŸš€ Google Colabì—ì„œ Transformers ëª¨ë¸ í•™ìŠµ ì‹œ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ í•´ê²°"
description: "Google Colab í™˜ê²½ì—ì„œ Transformers ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ê³¼ì •ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ì˜¤ë¥˜ë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì„¤ëª…. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë¬¸ì œ, íŒŒì¼ ê²½ë¡œ ì„¤ì •, ë°ì´í„° ì „ì²˜ë¦¬ ë° íŒ¨ë”© ë¬¸ì œ í•´ê²° ë“±ì„ í¬í•¨."
date: 2024-11-08
update: 2024-11-08
tags:
  - Code N Solve
  - Google Colab
  - Transformers
  - Hugging Face
  - NLP ëª¨ë¸
  - ë°ì´í„° ì „ì²˜ë¦¬
  - ì˜¤ë¥˜ í•´ê²°
series: "Code N Solve"
---

## Code N Solve ğŸ“˜: Google Colabì—ì„œ Transformers ëª¨ë¸ í•™ìŠµ ì‹œ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ í•´ê²° ê°€ì´ë“œ

Transformer ê¸°ë°˜ NLP ëª¨ë¸ì„ Google Colabì—ì„œ í•™ìŠµí•˜ëŠ” ë„ì¤‘ ì´ˆë³´ìê°€ ê²ªì„ ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ì˜¤ë¥˜ì— ëŒ€í•´ ì •ë¦¬í•´ë³´ì•˜ë‹¤.

íŠ¹íˆ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë¬¸ì œ, íŒŒì¼ ê²½ë¡œ ì„¤ì •, ë°ì´í„° ì „ì²˜ë¦¬ ë¬¸ì œ ë“± ë‹¤ì–‘í•œ ì˜¤ë¥˜ë¥¼ ì´í•´í•˜ê³  í•´ê²°í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ì.

### Google Colab?

- í´ë¼ìš°ë“œ ê¸°ë°˜ì˜ Jupyter ë…¸íŠ¸ë¶ í™˜ê²½ìœ¼ë¡œ, Python ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê³  ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ë° ìœ ìš©í•˜ë‹¤.
- íŠ¹íˆ, GPUë¥¼ ë¬´ë£Œë¡œ ì œê³µí•˜ì—¬ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì„ ë‹¤ë£¨ëŠ”ë° í° ì¥ì ì„ ê°€ì§€ê³  ìˆë‹¤.

### Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ [^1]

- Hugging Face[^2]ì—ì„œ ì œê³µí•˜ëŠ” ìì—°ì–´ ì²˜ë¦¬ (NLP) ëª¨ë¸ì„ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ë„êµ¬ì´ë‹¤.

## ë¬¸ì œ1: ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì˜¤ë¥˜ - `sklearn`ê³¼ `datasets`

- Google Colabì—ì„œ Transformers ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•˜ë ¤ë©´ `Hugging Face transformers`, `torch`, `datasets` ë“±ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•˜ë‹¤.
- í•˜ì§€ë§Œ `sklearn`ì„ ì„¤ì¹˜í•  ë•Œ ë‹¤ìŒê³¼ ê°™ì€ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤.

  ```bash
    ValueError: metadata-generation-failed
  ```

- ì´ ì˜¤ë¥˜ëŠ” `sklearn` ëŒ€ì‹  `scikit-learn`ì„ ì„¤ì¹˜í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ë°œìƒí•œë‹¤.

### í•´ê²° ë°©ë²•

- `sklearn` ëŒ€ì‹  `scikit-learn`ì„ ì„¤ì¹˜í•œë‹¤.[^3]

  ```bash
    !pip install -U scikit-learn
  ```

- ê·¸ ì™¸ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë„ í•œ ë²ˆì— ì„¤ì¹˜í•œë‹¤.

  ```bash
    !pip install transformers torch datasets
  ```

- ì´ì œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ê´€ë ¨ ì˜¤ë¥˜ëŠ” í•´ê²°ëœë‹¤.

## ë¬¸ì œ 2: Google Drive íŒŒì¼ ê²½ë¡œ ì„¤ì • ë¬¸ì œ[^4]

- ë°ì´í„°ì…‹ì„ Colabì—ì„œ ì‚¬ìš©í•˜ë ¤ë©´ Google Driveì— ì €ì¥ëœ íŒŒì¼ì„ Colabì— ì—°ê²°í•´ì•¼ í•œë‹¤.
- Colabì— Driveë¥¼ ë§ˆìš´íŠ¸í•˜ì§€ ì•Šìœ¼ë©´ `FileNotFoundError` ì˜¤ë¥˜ê°€ ë°œìƒí•œë‹¤.

### í•´ê²° ë°©ë²•

- Google Driveë¥¼ Colabì— ë§ˆìš´íŠ¸í•œë‹¤.

  ```python
    from google.colab import drive
    drive.mount('/content/drive')
  ```

- íŒŒì¼ ê²½ë¡œë¥¼ Google Drive ê²½ë¡œë¡œ ì§€ì •í•œë‹¤.

  - ì˜ˆë¥¼ ë“¤ì–´, `Dataset.json` íŒŒì¼ì´ Google Driveì˜ `Dataset` í´ë”ì— ìˆë‹¤ë©´, ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •í•œë‹¤.

  ```python
    import pandas as pd
    file_path = "/content/drive/MyDrive/Dataset/Dataset.json"
    data = pd.read_json(file_path, lines=True)
  ```

  - `/content/drive/`ëŠ” Google Driveì— ë§ˆìš´íŠ¸í–ˆì„ë•Œì˜ ê¸°ë³¸ ê²½ë¡œë‹¤.

## ë¬¸ì œ 3: Transformers ëª¨ë¸ í•™ìŠµ ì‹œ ë°ì´í„° íŒ¨ë”© ì˜¤ë¥˜[^2]

- ëª¨ë¸ í•™ìŠµ ì¤‘ ë°°ì¹˜ ë°ì´í„°ì˜ ê¸¸ì´ê°€ ì¼ì •í•˜ì§€ ì•Šìœ¼ë©´ `ValueError: expected sequence of length ...` ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤.
- ì´ëŠ” ë°ì´í„°ì˜ ê¸¸ì´ê°€ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— ë°œìƒí•œë‹¤.

### í•´ê²° ë°©ë²•

- ëª¨ë“  ì…ë ¥ ë°ì´í„°ì˜ ê¸¸ì´ë¥¼ ë§ì¶”ê¸° ìœ„í•´ `DataCollatorWithPadding`ì„ ì‚¬ìš©í•œë‹¤.

```python
  from transformers import DataCollatorWithPadding

  data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

  trainer = Trainer(
      model=model,
      args=training_args,
      train_dataset=tokenized_dataset,
      data_collator=data_collator,  # ìë™ íŒ¨ë”© ì¶”ê°€
  )
```

- ì´ë ‡ê²Œ ì„¤ì •í•˜ë©´, `Trainer`ê°€ ë°ì´í„°ì˜ ê¸¸ì´ë¥¼ ìë™ìœ¼ë¡œ ë§ì¶° ì˜¤ë¥˜ë¥¼ ë°©ì§€í•  ìˆ˜ ìˆë‹¤.

## ë¬¸ì œ 4: ëª¨ë¸ í•™ìŠµ ì‹œ `wandb` ë¡œê·¸ì¸ ìš”ì²­[^5]

- Hugging Face `Trainer`ëŠ” Weights & Biases(`wandb`)ë¥¼ ì‚¬ìš©í•´ í•™ìŠµ ê³¼ì •ì„ ì¶”ì í•  ìˆ˜ ìˆë‹¤.
- í•˜ì§€ë§Œ ë¡œê·¸ì¸ ìš”ì²­ì´ ë‚˜íƒ€ë‚  ìˆ˜ ìˆë‹¤.

### í•´ê²° ë°©ë²•

- `wandb` ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë ¤ë©´ `Trainer` ì„¤ì •ì—ì„œ `report_to="none"`ìœ¼ë¡œ ì§€ì •í•˜ì—¬ ë¹„í™œì„±í™”í•œë‹¤.

```python
  training_args = TrainingArguments(
      output_dir="./results",
      evaluation_strategy="epoch",
      per_device_train_batch_size=8,
      per_device_eval_batch_size=8,
      num_train_epochs=3,
      weight_decay=0.01,
      report_to="none"  # wandb ë¹„í™œì„±í™”
  )
```

- ì´ë ‡ê²Œ ì„¤ì •í•˜ë©´ `wandb` ë¡œê·¸ì¸ ìš”ì²­ ì—†ì´ í•™ìŠµì´ ì§„í–‰ëœë‹¤.

## ê²°ë¡ 

Google Colabì—ì„œ Transformers ëª¨ë¸ì„ í•™ìŠµí•˜ë©´ì„œ ë°œìƒí•˜ëŠ” ì£¼ìš” ì˜¤ë¥˜ë“¤ì„ í•´ê²°í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ì•˜ë‹¤.

ê° ë‹¨ê³„ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¬¸ì œë“¤ì„ ì´í•´í•˜ê³  ì´ë¥¼ í•´ê²°í•´ ë‚˜ê°€ë©´, Colab í™˜ê²½ì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆë‹¤.

ì´ ê¸€ì„ í†µí•´ Google Colabì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ , ë³´ë‹¤ ì•ˆì •ì ìœ¼ë¡œ NLP ëª¨ë¸ì„ í•™ìŠµí•  ìˆ˜ ìˆê¸°ë¥¼ ë°”ëë‹ˆë‹¤.

[^1]: https://wikidocs.net/book/8056
[^2]: https://huggingface.co/learn/nlp-course/ko/chapter8/2
[^3]: https://heekangpark.github.io/ml/shorts/scikit-learn-basics
[^4]: https://wikidocs.net/226032
[^5]: https://discuss.huggingface.co/t/how-to-turn-wandb-off-in-trainer/6237
